{
  "app": {
    "title": "ğŸ›ï¸ ACE-Step V1.5 PlaygroundğŸ’¡",
    "subtitle": "Pushing the Boundaries of Open-Source Music Generation"
  },
  "common": {},
  "dataset": {
    "title": "ğŸ“Š Dataset Explorer",
    "dataset_label": "Dataset",
    "dataset_info": "Choose dataset to explore.",
    "import_btn": "ğŸ“¥ Import Dataset",
    "search_type_label": "Search Type",
    "search_type_info": "How to find items.",
    "search_value_label": "Search Value",
    "search_value_placeholder": "Enter keys or index (leave empty for random)",
    "search_value_info": "Keys: exact match, Index: 0 to dataset size-1.",
    "instruction_label": "ğŸ“ Instruction",
    "instruction_placeholder": "No instruction available",
    "metadata_title": "ğŸ“‹ Item Metadata (JSON)",
    "metadata_label": "Complete Item Information",
    "source_audio": "Source Audio",
    "target_audio": "Target Audio",
    "reference_audio": "Reference Audio",
    "get_item_btn": "ğŸ” Get Item",
    "use_src_checkbox": "Use Source Audio from Dataset",
    "use_src_info": "Check to use the source audio from dataset.",
    "data_status_label": "ğŸ“Š Data Status",
    "data_status_default": "âŒ No dataset imported",
    "autofill_btn": "ğŸ“‹ Auto-fill Generation Form"
  },
  "service": {
    "title": "ğŸ”§ Service Configuration",
    "checkpoint_label": "Checkpoint File",
    "checkpoint_info": "Select a trained model checkpoint file (full path or filename).",
    "refresh_btn": "ğŸ”„ Refresh",
    "model_path_label": "Main Model Path",
    "model_path_info": "Select the model configuration directory (auto-scanned from checkpoints).",
    "device_label": "Device",
    "device_info": "Processing device (auto-detect recommended).",
    "lm_model_path_label": "5Hz LM Model Path",
    "lm_model_path_info": "Select the 5Hz LM model checkpoint (auto-scanned from checkpoints).",
    "backend_label": "5Hz LM Backend",
    "backend_info": "Select backend for 5Hz LM: vllm (faster) or pt (PyTorch, more compatible).",
    "init_llm_label": "Initialize 5Hz LM",
    "init_llm_info": "Check to initialize 5Hz LM during service initialization.",
    "flash_attention_label": "Use Flash Attention",
    "flash_attention_info_enabled": "Enable flash attention for faster inference (requires flash_attn package).",
    "flash_attention_info_disabled": "Flash attention not available (flash_attn package not installed).",
    "offload_cpu_label": "Offload to CPU",
    "offload_cpu_info": "Offload models to CPU when not in use to save GPU memory.",
    "offload_dit_cpu_label": "Offload DiT to CPU",
    "offload_dit_cpu_info": "Offload DiT to CPU (needs Offload to CPU).",
    "compile_model_label": "Compile Model",
    "compile_model_info": "Use torch.compile to optimize model (required for quantization).",
    "quantization_label": "INT8 Quantization",
    "quantization_info": "Enable INT8 weight-only quantization to reduce VRAM usage (requires Compile Model).",
    "mlx_dit_label": "MLX DiT (Apple Silicon)",
    "mlx_dit_info_enabled": "Use native MLX for DiT diffusion on Apple Silicon (faster than MPS).",
    "mlx_dit_info_disabled": "MLX not available (requires macOS + Apple Silicon + mlx package).",
    "init_btn": "Initialize Service",
    "status_label": "Status",
    "language_label": "UI Language",
    "language_info": "Select interface language.",
    "gpu_auto_tier": "Auto-detected Tier",
    "tier_label": "GPU Tier Override",
    "tier_info": "Manually select GPU tier to adjust optimization defaults (offload, quantization, backend, etc.)."
  },
  "generation": {
    "tab_title": "ğŸµ Generation",
    "required_inputs": "ğŸ“ Required Inputs",
    "task_type_label": "Task Type *",
    "task_type_info": "Select the task type for generation.",
    "instruction_label": "Instruction",
    "instruction_info": "Instruction is automatically generated based on task type.",
    "load_btn": "ğŸ“‚ Load",
    "track_name_label": "Track Name",
    "track_name_info": "Select track name for lego/extract tasks.",
    "track_classes_label": "Track Names",
    "track_classes_info": "Select multiple track classes for complete task.",
    "audio_uploads": "ğŸµ Audio Uploads",
    "reference_audio": "Reference Audio",
    "source_audio": "Source Audio",
    "convert_codes_btn": "Convert to Codes",
    "analyze_btn": "ğŸ” Analyze",
    "sample_btn": "ğŸ² Click Me",
    "lm_codes_hints": "ğŸ¼ LM Codes Hints",
    "lm_codes_label": "LM Codes Hints",
    "lm_codes_placeholder": "<|audio_code_10695|><|audio_code_54246|>.",
    "lm_codes_info": "Paste LM codes hints for text2music generation.",
    "lm_codes_sample": "LM Codes Hints (Sample {n})",
    "lm_codes_sample_info": "Codes for sample {n}.",
    "transcribe_btn": "Transcribe",
    "repainting_controls": "ğŸ¨ Repainting Controls (seconds)",
    "repainting_start": "Repainting Start",
    "repainting_end": "Repainting End",
    "mode_label": "Generation Mode *",
    "mode_info": "Select a generation mode to get started.",
    "mode_info_simple": "Describe your music in natural language. AI will generate caption, lyrics and metadata for you.",
    "mode_info_custom": "Full control over caption, lyrics and all parameters.",
    "mode_info_remix": "Upload source audio to create a remix version with your caption and lyrics.",
    "mode_info_repaint": "Upload source audio and repaint a specific time range.",
    "mode_info_extract": "Extract a specific track (vocals, drums, etc.) from source audio.",
    "mode_info_lego": "Reassemble tracks: replace a specific track in the source audio.",
    "mode_info_complete": "Complete missing tracks in the source audio.",
    "mode_simple": "Simple",
    "mode_custom": "Custom",
    "simple_query_label": "Song Description *",
    "simple_query_placeholder": "Describe the music you want to create, e.g., 'a soft Bengali love song for a quiet evening'. Leave empty for a random sample.",
    "simple_query_info": "Enter a natural language description of the music you want to generate.",
    "simple_vocal_language_label": "Vocal Language",
    "simple_vocal_language_info": "Select preferred language(s) for lyrics. Use 'unknown' for any language.",
    "create_sample_btn": "Create Sample",
    "caption_title": "ğŸ“ Music Caption",
    "caption_label": "Music Caption",
    "caption_placeholder": "A peaceful acoustic guitar melody with soft vocals.",
    "caption_info": "Describe the style, genre, instruments, and mood.",
    "lyrics_title": "ğŸ“ Lyrics",
    "lyrics_label": "Lyrics",
    "lyrics_placeholder": "[Verse 1]\\nUnder the starry night\\nI feel so alive.",
    "lyrics_info": "Song lyrics with structure.",
    "instrumental_label": "Instrumental",
    "format_btn": "Format",
    "format_caption_btn": "Enhance Caption",
    "format_lyrics_btn": "Enhance Lyrics",
    "optional_params": "âš™ï¸ Optional Parameters",
    "optional_music_props": "ğŸµ Music Properties",
    "optional_gen_settings": "ğŸ“ Generation Settings",
    "advanced_dit_section": "ğŸ›ï¸ DiT Diffusion",
    "advanced_lm_section": "ğŸ¤– LM Generation",
    "advanced_output_section": "ğŸ”Š Audio Output & Post-processing",
    "advanced_automation_section": "âš¡ Automation & Batch",
    "vocal_language_label": "Vocal Language",
    "vocal_language_info": "'unknown' = instrumental / auto.",
    "bpm_label": "BPM",
    "bpm_info": "Leave empty for N/A.",
    "keyscale_label": "Key",
    "keyscale_placeholder": "Leave empty for N/A",
    "keyscale_info": "A-G, #/â™­, major/minor.",
    "timesig_label": "Time Signature",
    "timesig_info": "2/4, 3/4, 4/4.",
    "duration_label": "Audio Duration (seconds)",
    "duration_info": "Use -1 for random.",
    "batch_size_label": "Batch Size",
    "batch_size_info": "Number of audio to generate (max 8).",
    "advanced_settings": "âš™ï¸ Settings",
    "inference_steps_label": "DiT Inference Steps",
    "inference_steps_info": "Turbo: max 8, Base: max 200.",
    "guidance_scale_label": "DiT Guidance Scale (Only support for base model)",
    "guidance_scale_info": "Higher values follow text more closely.",
    "seed_label": "Seed",
    "seed_info": "Use comma-separated values for batches.",
    "random_seed_label": "Random Seed",
    "random_seed_info": "Enable to auto-generate seeds.",
    "audio_format_label": "Audio Format",
    "audio_format_info": "Audio format for saved files.",
    "use_adg_label": "Use ADG",
    "use_adg_info": "Enable Angle Domain Guidance.",
    "shift_label": "Shift",
    "shift_info": "Timestep shift factor for base models (range 1.0~5.0, default 3.0). Not effective for turbo models.",
    "infer_method_label": "Inference Method",
    "infer_method_info": "Diffusion inference method. ODE (Euler) is faster, SDE (stochastic) may produce different results.",
    "custom_timesteps_label": "Custom Timesteps",
    "custom_timesteps_info": "Comma-separated values from 1.0 to 0.0 (e.g., '0.97,0.76,0.615,0.5,0.395,0.28,0.18,0.085,0'). Overrides inference steps and shift.",
    "cfg_interval_start": "CFG Interval Start",
    "cfg_interval_end": "CFG Interval End",
    "lm_params_title": "ğŸ¤– LM Generation Parameters",
    "lm_temperature_label": "LM Temperature",
    "lm_temperature_info": "5Hz LM temperature (higher = more random).",
    "lm_cfg_scale_label": "LM CFG Scale",
    "lm_cfg_scale_info": "5Hz LM CFG (1.0 = no CFG).",
    "lm_top_k_label": "LM Top-K",
    "lm_top_k_info": "Top-K (0 = disabled).",
    "lm_top_p_label": "LM Top-P",
    "lm_top_p_info": "Top-P (1.0 = disabled).",
    "lm_negative_prompt_label": "LM Negative Prompt",
    "lm_negative_prompt_placeholder": "Enter negative prompt for CFG (default: NO USER INPUT)",
    "lm_negative_prompt_info": "Negative prompt (use when LM CFG Scale > 1.0).",
    "advanced_dit_params": "Advanced DiT Parameters",
    "cot_metas_label": "CoT Metas",
    "cot_metas_info": "Use LM to generate CoT metadata (uncheck to skip LM CoT generation).",
    "cot_language_label": "CoT Language",
    "cot_language_info": "Generate language in CoT (chain-of-thought).",
    "constrained_debug_label": "Constrained Decoding Debug",
    "constrained_debug_info": "Enable debug logging for constrained decoding (check to see detailed logs).",
    "auto_score_label": "Auto Score",
    "auto_score_info": "Automatically calculate quality scores for all generated audios.",
    "auto_lrc_label": "Auto LRC",
    "auto_lrc_info": "Automatically generate LRC lyrics timestamps for all generated audios.",
    "lm_batch_chunk_label": "LM Batch Chunk Size",
    "lm_batch_chunk_info": "Max items per LM batch chunk (default: 8, limited by GPU memory).",
    "codes_strength_label": "LM Codes Strength",
    "codes_strength_info": "Control how many denoising steps use LM-generated codes.",
    "cover_strength_label": "Audio Cover Strength",
    "cover_strength_info": "Control how many denoising steps use cover mode.",
    "remix_strength_label": "Remix Strength",
    "remix_strength_info": "Control how closely the remix follows the source audio (higher = closer to original).",
    "cover_noise_strength_label": "Cover Strength",
    "cover_noise_strength_info": "Controls melody retention in Remix mode. Recommended: use the SFT model with a value of 0.1â€“0.25. A small increase restores the melody, but style transfer may require additional prompt tuning. (0 = pure noise/no cover, 1 = closest to original audio).",
    "score_sensitivity_label": "Quality Score Sensitivity",
    "score_sensitivity_info": "Lower = more sensitive (default: 1.0). Adjusts how PMI maps to [0,1].",
    "think_label": "Think",
    "parallel_thinking_label": "ParallelThinking",
    "parallel_thinking_info": "Process batch samples in parallel for faster generation.",
    "generate_btn": "ğŸµ Generate Music",
    "extract_stem_btn": "ğŸµ Extract Stem",
    "add_stem_btn": "ğŸµ Add Stem",
    "stem_area_controls": "ğŸ§© New Stem Area (seconds)",
    "stem_start": "Stem Start",
    "stem_end": "Stem End",
    "autogen_label": "AutoGen",
    "caption_rewrite_label": "CaptionRewrite",
    "caption_rewrite_info": "Use LM to rewrite caption before generation.",
    "auto_label": "Auto",
    "bpm_auto_label": "BPM Auto",
    "key_auto_label": "Key Auto",
    "timesig_auto_label": "TimeSig Auto",
    "vocal_lang_auto_label": "Language Auto",
    "duration_auto_label": "Duration Auto",
    "reset_all_auto": "ğŸ”„ Reset All to Auto"
  },
  "results": {
    "title": "ğŸµ Results",
    "generated_music": "ğŸµ Generated Music (Sample {n})",
    "send_to_remix_btn": "ğŸ”— Send To Remix",
    "send_to_repaint_btn": "ğŸ”— Send To Repaint",
    "save_btn": "ğŸ’¾ Save",
    "score_btn": "ğŸ“Š Get Score",
    "lrc_btn": "ğŸµ Get LRC",
    "save_lrc_btn": "ğŸ’¾ Save LRC",
    "convert_to_codes_btn": "ğŸ”„ Convert To Codes",
    "quality_score_label": "Quality Score (Sample {n})",
    "quality_score_placeholder": "Click 'Score' to calculate perplexity-based quality score",
    "codes_label": "LM Codes (Sample {n})",
    "lrc_label": "Lyrics Timestamps (Sample {n})",
    "lrc_placeholder": "Click 'LRC' to generate timestamps",
    "details_accordion": "ğŸ“Š Score & LRC & LM Codes",
    "generation_status": "Generation Status",
    "current_batch": "Current Batch",
    "batch_indicator": "Batch {current} / {total}",
    "next_batch_status": "Next Batch Status",
    "prev_btn": "â—€ Previous",
    "next_btn": "Next â–¶",
    "restore_params_btn": "â†™ï¸ Apply These Settings to UI (Restore Batch Parameters)",
    "batch_results_title": "ğŸ“ Batch Results & Generation Details",
    "all_files_label": "ğŸ“ All Generated Files (Download)",
    "generation_details": "Generation Details"
  },
  "messages": {
    "no_audio_to_save": "âŒ No audio to save",
    "save_success": "âœ… Saved audio and metadata to {filename}",
    "save_failed": "âŒ Failed to save: {error}",
    "no_file_selected": "âš ï¸ No file selected",
    "params_loaded": "âœ… Parameters loaded from {filename}",
    "invalid_json": "âŒ Invalid JSON file: {error}",
    "load_error": "âŒ Error loading file: {error}",
    "example_loaded": "ğŸ“ Loaded example from {filename}",
    "example_failed": "Failed to parse JSON file {filename}: {error}",
    "example_error": "Error loading example: {error}",
    "lm_generated": "ğŸ¤– Generated example using LM",
    "lm_fallback": "Failed to generate example using LM, falling back to examples directory",
    "lm_not_initialized": "âŒ 5Hz LM not initialized. Please initialize it first.",
    "think_requires_lm": "âš ï¸ 'Think' requires 5Hz LM to be initialized. Think has been disabled â€” generation will proceed without LM thinking.",
    "autogen_enabled": "ğŸ”„ AutoGen enabled - next batch will generate after this",
    "batch_ready": "âœ… Batch {n} ready! Click 'Next' to view.",
    "batch_generating": "ğŸ”„ Starting background generation for Batch {n}.",
    "batch_failed": "âŒ Background generation failed: {error}",
    "viewing_batch": "âœ… Viewing Batch {n}",
    "at_first_batch": "Already at first batch",
    "at_last_batch": "No next batch available",
    "batch_not_found": "Batch {n} not found in queue",
    "no_batch_data": "No batch data found to restore.",
    "params_restored": "âœ… UI Parameters restored from Batch {n}",
    "scoring_failed": "âŒ Error: Batch data not found",
    "no_codes": "âŒ No audio codes available. Please generate music first.",
    "score_failed": "âŒ Scoring failed: {error}",
    "score_error": "âŒ Error calculating score: {error}",
    "lrc_no_batch_data": "âŒ No batch data found. Please generate music first.",
    "lrc_no_extra_outputs": "âŒ No extra outputs found. Condition tensors not available.",
    "lrc_missing_tensors": "âŒ Missing required tensors for LRC generation.",
    "lrc_sample_not_exist": "âŒ Sample does not exist in current batch.",
    "lrc_empty_result": "âš ï¸ LRC generation produced empty result.",
    "empty_query": "âš ï¸ Please enter a music description.",
    "sample_creation_failed": "âŒ Failed to create sample. Please try again.",
    "sample_created": "âœ… Sample created! Review the caption and lyrics, then click Generate Music.",
    "simple_examples_not_found": "âš ï¸ Simple mode examples directory not found.",
    "simple_examples_empty": "âš ï¸ No example files found in simple mode examples.",
    "simple_example_loaded": "ğŸ² Loaded random example from {filename}",
    "format_success": "âœ… Caption and lyrics formatted successfully",
    "format_failed": "âŒ Format failed: {error}",
    "skipping_metas_cot": "âš¡ Skipping Phase 1 metas COT (sample already formatted)",
    "invalid_timesteps_format": "âš ï¸ Invalid timesteps format. Using default schedule.",
    "timesteps_out_of_range": "âš ï¸ Timesteps must be in range [0, 1]. Using default schedule.",
    "timesteps_count_mismatch": "âš ï¸ Timesteps count ({actual}) differs from inference_steps ({expected}). Using timesteps count.",
    "audio_format_invalid": "{role} format is invalid or unsupported. Please upload a valid audio file."
  },
  "training": {
    "tab_title": "ğŸ“ LoRA Training",
    "tab_dataset_builder": "ğŸ“ Dataset Builder",
    "tab_train_lora": "ğŸš€ Train LoRA",
    "quick_start_title": "ğŸš€ Quick Start",
    "load_dataset_label": "Dataset JSON Path",
    "load_dataset_info": "Load a previously saved dataset.",
    "load_btn": "ğŸ“‚ Load",
    "load_status": "Load Status",
    "scan_label": "Audio Directory Path",
    "scan_info": "Scan for audio files (wav, mp3, flac, ogg, opus).",
    "scan_btn": "ğŸ” Scan",
    "scan_status": "Scan Status",
    "found_audio_files": "Found Audio Files",
    "dataset_name": "Dataset Name",
    "dataset_name_placeholder": "Enter dataset name",
    "dataset_settings_header": "Dataset Settings",
    "tag_prepend": "Prepend (Tag, Caption)",
    "tag_append": "Append (Caption, Tag)",
    "tag_replace": "Replace Caption",
    "step2_title": "Step 2: AI Auto-Labeling",
    "step2_instruction": "Click the button below to use AI to automatically generate metadata for all audio files:\n- **Caption**: Music style, genre, mood description\n- **BPM**: Beats per minute\n- **Key**: Music key (e.g. C Major, Am)\n- **Time Signature**: 4/4, 3/4 etc.",
    "step3_title": "Step 3: Preview & Edit",
    "step4_title": "Step 4: Save Dataset",
    "step5_title": "Step 5: Preprocess to Tensors",
    "step5_intro": "**Preprocessing converts your dataset into pre-computed tensors for fast training.**\n\nYou can:\n- Use the dataset from steps 1-4 above, **OR**\n- Load an existing dataset JSON file (if you have one saved)",
    "step5_details": "This step will:\n- Encode audio to VAE latents\n- Encode captions and lyrics to text embeddings\n- Run condition encoders\n- Save all tensors to `.pt` files\n\nâš ï¸ **This requires loading models and may take a few minutes.**",
    "train_tensor_selection_desc": "Select the directory containing preprocessed tensor files (`.pt` files).\nThese are created using the 'Preprocess' button in the 'Dataset Builder' tab.",
    "all_instrumental": "All Instrumental",
    "all_instrumental_info": "Check if all tracks are instrumental (no vocals).",
    "custom_tag": "Custom Trigger Tag",
    "custom_tag_info": "Unique tag to activate this LoRA style.",
    "tag_position": "Tag Position",
    "tag_position_info": "Where to place the custom tag in the caption.",
    "genre_ratio": "Genre Ratio (%)",
    "genre_ratio_info": "0%=All Caption, 100%=All Genre. Single sample override takes precedence.",
    "skip_metas": "Skip BPM/Key/TimeSig",
    "skip_metas_info": "Skip BPM/Key/TimeSig generation. Captions and genres are still generated by LM.",
    "only_unlabeled": "Only Unlabeled",
    "only_unlabeled_info": "Only label samples with no caption (for continuing failed labeling).",
    "auto_label_btn": "ğŸ·ï¸ Auto-Label All",
    "label_progress": "Labeling Progress",
    "select_sample": "Select Sample #",
    "select_sample_info": "Select sample to preview and edit.",
    "audio_preview": "Audio Preview",
    "filename": "Filename",
    "caption": "Caption",
    "genre": "Genre",
    "prompt_override_label": "Prompt Override (This Sample)",
    "prompt_override_info": "Override global ratio for this sample.",
    "lyrics_editable_label": "Lyrics (Editable for Training)",
    "raw_lyrics_label": "Raw Lyrics (from .txt file)",
    "no_lyrics_placeholder": "(No .txt lyrics file)",
    "bpm": "BPM",
    "key_label": "Key",
    "key_placeholder": "C Major",
    "time_sig": "Time Sig",
    "duration_s": "Duration (s)",
    "language": "Language",
    "instrumental": "Instrumental",
    "save_changes_btn": "ğŸ’¾ Save Changes",
    "edit_status": "Edit Status",
    "save_path": "Save Path",
    "save_path_info": "Path to save dataset JSON.",
    "save_dataset_btn": "ğŸ’¾ Save Dataset",
    "save_status": "Save Status",
    "load_existing_label": "Load Existing Dataset",
    "load_existing_info": "Path to previously saved dataset JSON file.",
    "load_dataset_btn": "ğŸ“‚ Load Dataset",
    "tensor_output_dir": "Tensor Output Directory",
    "tensor_output_info": "Directory to save preprocessed tensor files.",
    "preprocess_btn": "âš¡ Preprocess",
    "preprocess_progress": "Preprocessing Progress",
    "preprocessed_tensors_dir": "Preprocessed Tensors Directory",
    "preprocessed_tensors_info": "Directory containing preprocessed .pt tensor files.",
    "dataset_info": "Dataset Info.",
    "lora_rank": "LoRA Rank (r)",
    "lora_rank_info": "Higher capacity but more VRAM.",
    "lora_alpha": "LoRA Alpha",
    "lora_alpha_info": "Scaling factor (usually 2x Rank).",
    "lora_dropout": "LoRA Dropout",
    "learning_rate": "Learning Rate",
    "learning_rate_info": "Start with 3e-4, adjust as needed.",
    "max_epochs": "Max Epochs",
    "batch_size": "Batch Size",
    "batch_size_info": "Increase if VRAM allows.",
    "gradient_accumulation": "Gradient Accumulation",
    "gradient_accumulation_info": "Effective Batch Size = batch_size * accum_steps.",
    "save_every_n_epochs": "Save Every N Epochs",
    "shift": "Shift",
    "shift_info": "Timestep shift for Turbo models.",
    "seed": "Seed",
    "output_dir": "Output Directory",
    "output_dir_info": "Directory to save trained LoRA weights.",
    "start_training_btn": "ğŸš€ Start Training",
    "stop_training_btn": "â¹ï¸ Stop Training",
    "training_progress": "Training Progress",
    "training_log": "Training Log",
    "training_loss_title": "Training Loss",
    "step": "Step",
    "loss": "Loss",
    "export_header": "Export LoRA",
    "export_path": "Export Path",
    "export_lora_btn": "ğŸ“¦ Export LoRA",
    "export_status": "Export Status",
    "stop_no_training": "\u2139 No training in progress",
    "stop_stopping": "\u23F9\uFE0F Stopping training...",
    "latest_auto": "Latest (auto)",
    "export_path_required": "\u274C Please enter an export path",
    "invalid_lora_output_dir": "\u274C Invalid LoRA output directory",
    "no_checkpoints_found": "\u274C No checkpoints found",
    "no_trained_model_found": "\u274C No trained model found in {path}",
    "invalid_export_path": "\u274C Invalid export path",
    "lora_exported": "\u2705 LoRA exported to {path}",
    "export_failed": "\u274C Export failed: {error}",
    "lokr_output_dir_required": "\u26A0\uFE0F Enter LoKr output directory first",
    "lokr_no_checkpoints_use_latest": "\u2139 No checkpoints found; export will use latest available weights",
    "lokr_no_exportable_checkpoints": "\u2139 No exportable epoch checkpoints found",
    "lokr_found_checkpoints": "\u2705 Found {count} LoKr checkpoints",
    "lokr_selected_epoch_not_found": "\u274C Selected epoch not found: {chosen}. Available: {available}",
    "lokr_no_weights_selected_epoch": "\u274C No LoKr weights found for selected epoch: {epoch}",
    "lokr_no_weights_latest_checkpoint": "\u274C No LoKr weights found in latest checkpoint: {checkpoint}",
    "lokr_no_trained_weights_found": "\u274C No trained LoKr weights found in {path}",
    "lokr_exported": "\u2705 LoKr exported to {path}"
  },
  "help": {
    "btn_label": "?",
    "close_label": "âœ•",
    "getting_started": "## Getting Started\n\n1. **Select a model** in the Settings accordion (e.g. `acestep-v15-turbo`)\n2. **Choose a 5Hz LM** if you want Thinking mode (recommended)\n3. Click **Initialize Service** and wait for the green status\n4. Pick a **Generation Mode** (start with Simple)\n5. Describe your music and click **Generate Music**\n\n> **Tip:** Turbo models are fastest. Enable \"Think\" for smarter generation.",
    "service_config": "## Service Configuration\n\n### Quick Setup\n1. Select **Main Model Path** (turbo recommended)\n2. Select **5Hz LM Model Path** (auto-filtered by GPU)\n3. Choose **Backend**: `vllm` (fast, NVIDIA â‰¥8GB) or `pt` (universal)\n4. Check **Initialize 5Hz LM** for Thinking mode\n5. Click **Initialize Service**\n\n### Performance Tips\n- **Flash Attention**: Faster inference (needs flash_attn)\n- **CPU Offload**: Auto-enabled on GPUs <20GB\n- **INT8 Quantization**: Reduces VRAM, auto-enabled <20GB\n- **Compile**: Required for quantization, enabled by default\n\n### LoRA\n- Set LoRA path â†’ Load â†’ Enable \"Use LoRA\"\n- âš ï¸ Cannot use LoRA with INT8 quantization",
    "generation_simple": "## Simple Mode Tutorial\n\n**Best for:** Quick music creation with minimal effort.\n\n### Steps\n1. Select **Simple** in Generation Mode\n2. Type a description, e.g. *\"upbeat pop song with catchy guitar riff\"*\n3. (Optional) Check **Instrumental** for no vocals\n4. (Optional) Select **Vocal Language**\n5. Click **Create Sample** â€” AI generates caption, lyrics, metadata\n6. Review and edit the generated content if needed\n7. Click **Generate Music**\n\n### Tips\n- Click ğŸ² for random inspiration\n- The more specific your description, the better the result\n- Leave BPM/Key empty to let AI decide",
    "generation_custom": "## Custom Mode Tutorial\n\n**Best for:** Full creative control over every parameter.\n\n### Steps\n1. Select **Custom** in Generation Mode\n2. Write a detailed **Caption** describing style, genre, instruments, mood\n3. Write **Lyrics** with structure tags: `[Verse]`, `[Chorus]`, `[Bridge]`\n4. (Optional) Upload **Reference Audio** for style guidance\n5. Set **BPM**, **Key**, **Duration** or leave empty for auto\n6. Click **Format** to enhance with LM (optional)\n7. Click **Generate Music**\n\n### Caption Tips\n- Be specific: *\"dreamy shoegaze with reverb-heavy guitars and whispered vocals\"*\n- Include: genre, instruments, mood, tempo feel, vocal style",
    "generation_remix": "## Remix Mode Tutorial\n\n**Best for:** Creating cover versions or style transfers.\n\n### Steps\n1. Select **Remix** in Generation Mode\n2. Upload **Source Audio** (the song to remix)\n3. Write a **Caption** describing the target style\n4. (Optional) Modify **Lyrics**\n5. Adjust **Remix Strength** (0.0â€“1.0):\n   - Higher = closer to original structure\n   - Lower = more creative freedom\n6. Click **Generate Music**\n\n### Tips\n- Start with strength 0.5 and adjust\n- Use SFT model with Cover Strength 0.1â€“0.25 for melody retention",
    "generation_repaint": "## Repaint Mode Tutorial\n\n**Best for:** Fixing specific sections of generated music.\n\n### Steps\n1. Select **Repaint** in Generation Mode\n2. Upload **Source Audio**\n3. Set **Repainting Start** (seconds) and **End** (-1 for end of file)\n4. Write a **Caption** for the repainted section\n5. Click **Generate Music**\n\n### Tips\n- Use \"Send To Repaint\" from Results to quickly load audio\n- Keep the repaint range focused for best results\n- Good for fixing vocals, changing instruments in a section",
    "generation_extract": "## Extract Mode (Base Model Only)\n\n**Best for:** Stem separation â€” isolating instruments from a mix.\n\n### Steps\n1. Select **Extract** in Generation Mode\n2. Upload **Source Audio**\n3. Select **Track Name** to extract (e.g. vocals, drums, bass)\n4. Click **Extract Stem**\n\n### Available Tracks\nvocals, backing_vocals, drums, bass, guitar, keyboard, percussion, strings, synth, fx, brass, woodwinds",
    "generation_lego": "## Lego Mode (Base Model Only)\n\n**Best for:** Adding new instrument tracks to existing audio.\n\n### Steps\n1. Select **Lego** in Generation Mode\n2. Upload **Source Audio**\n3. Select **Track Name** to add\n4. Write a **Caption** describing the track\n5. Click **Add Stem**\n\n### Tips\n- Great for layering: add drums to a guitar track, add bass to vocals\n- The caption should describe only the new track's characteristics",
    "generation_complete": "## Complete Mode (Base Model Only)\n\n**Best for:** Auto-arranging â€” filling in missing instruments.\n\n### Steps\n1. Select **Complete** in Generation Mode\n2. Upload **Source Audio** (partial arrangement)\n3. Select multiple **Track Names** to add\n4. Write a **Caption** describing the desired style\n5. Click **Generate Music**",
    "generation_caption": "## Writing Good Captions\n\n### Structure\nA good caption includes:\n- **Genre/Style**: pop, rock, jazz, electronic, classicalâ€¦\n- **Instruments**: guitar, piano, synth, drums, stringsâ€¦\n- **Mood**: upbeat, melancholic, energetic, dreamyâ€¦\n- **Vocal style**: whispered, powerful, falsetto, rapâ€¦\n- **Tempo feel**: fast, slow, moderate, drivingâ€¦\n\n### Examples\n- *\"Energetic pop-punk with distorted guitars, fast drums, and shouted vocals\"*\n- *\"Smooth jazz trio with walking bass, brushed drums, and mellow piano\"*\n- *\"Ambient electronic with layered synth pads and no vocals\"*\n\n### Tips\n- More detail = better results\n- Use the **Format** button to let AI enhance your caption\n- Check ğŸ² for example captions",
    "generation_lyrics": "## Writing Lyrics\n\n### Structure Tags\nUse section tags to structure your song:\n```\n[Verse 1]\nYour verse lyrics here\n\n[Chorus]\nYour chorus lyrics here\n\n[Verse 2]\nSecond verse here\n\n[Bridge]\nBridge section\n\n[Outro]\nEnding lyrics\n```\n\n### Tips\n- Keep verses 4â€“8 lines\n- Choruses should be memorable and repetitive\n- Use `[Instrumental]` or `[Interlude]` for non-vocal sections\n- Check **Instrumental** checkbox for pure instrumental music\n- Select **Vocal Language** to match your lyrics language",
    "generation_advanced": "## Advanced Settings\n\n### Key Parameters\n- **Inference Steps**: Turbo=8 (default), Base=up to 200. More steps â‰  always better for turbo\n- **Guidance Scale**: Base model only. Higher = follows prompt more strictly\n- **Shift**: Timestep shift (1.0â€“5.0). 3.0 recommended for turbo\n- **Seed**: Set a specific seed for reproducible results\n\n### LM Parameters\n- **Temperature** (0.0â€“2.0): Higher = more creative/random\n- **CFG Scale** (1.0â€“3.0): Higher = follows prompt more\n- **Top-K / Top-P**: Sampling strategies for diversity\n\n### Think Mode\nEnable **Think** to use 5Hz LM for smarter generation:\n- Generates semantic codes and metadata\n- Requires LM to be initialized\n- **ParallelThinking**: Process batches in parallel (faster)",
    "results": "## Results Section\n\n### Per-Sample Controls\n- **Audio Player**: Play, pause, download\n- **Send To Remix/Repaint**: Use this result as source for further editing\n- **Save**: Export audio + metadata as JSON\n- **Score**: Calculate quality score (perplexity-based)\n- **LRC**: Generate lyrics timestamps\n\n### Batch Navigation\n- Use **â—€ Previous** / **Next â–¶** to browse batches\n- Enable **AutoGen** to auto-generate next batch\n- Click **Apply These Settings to UI** to reuse parameters from a good result\n\n### Tips\n- Generate 2â€“4 variations (batch size) and pick the best\n- Use Score to objectively compare results\n- Save good results for reference",
    "training_dataset": "## Dataset Builder Tutorial\n\n### Step 1: Load or Scan\n- **Load**: Enter path to existing dataset JSON â†’ Click Load\n- **Scan**: Enter audio folder path â†’ Click Scan\n  - Supported: wav, mp3, flac, ogg, opus\n\n### Step 2: Configure\n- Set **Dataset Name**\n- Check **All Instrumental** if no vocals\n- Set **Custom Activation Tag** (unique trigger word for your LoRA)\n- Choose **Tag Position**: Prepend, Append, or Replace\n\n### Step 3: Auto-Label\n- Click **Auto-Label All** to generate captions, BPM, key, time sig\n- Use **Skip Metas** to skip BPM/Key/TimeSig (faster)\n\n### Step 4: Preview & Edit\n- Use slider to browse samples\n- Edit caption, lyrics, BPM, key manually\n- Click **Save Changes** per sample\n\n### Step 5: Save\n- Enter save path â†’ Click **Save Dataset**\n\n### Step 6: Preprocess\n- Set tensor output directory â†’ Click **Preprocess**\n- This encodes audio/text to tensors for training",
    "training_train": "## LoRA Training Tutorial\n\n### Setup\n1. Enter **Preprocessed Tensors Directory** â†’ Click **Load Dataset**\n2. Configure LoRA:\n   - **Rank** (r): 64 default. Higher = more capacity\n   - **Alpha**: Usually 2Ã— rank (128)\n   - **Dropout**: 0.1 for regularization\n\n### Training\n3. Set **Learning Rate** (start with 1e-4)\n4. Set **Max Epochs** (500 default)\n5. Click **Start Training**\n6. Monitor loss curve â€” it should decrease over time\n7. Click **Stop Training** when satisfied\n\n### Export\n8. Enter export path â†’ Click **Export LoRA**\n9. Load in Settings: set LoRA Path â†’ Load LoRA â†’ Enable Use LoRA\n\n### Tips\n- Use small batch size (1) if VRAM is limited\n- Gradient accumulation increases effective batch size\n- Save checkpoints frequently (every 200 epochs)",
    "training_export": "## Using Your Trained LoRA\n\n### Export\n1. After training, enter export path\n2. Click **Export LoRA**\n\n### Load & Use\n1. In Settings, set **LoRA Path** to your exported directory\n2. Click **Load LoRA**\n3. Enable **Use LoRA** checkbox\n4. Generate music â€” your LoRA style will be applied\n\n### Tips\n- Use your **Custom Activation Tag** in captions to trigger the style\n- âš ï¸ LoRA is incompatible with INT8 quantization\n- You can unload and switch between different LoRAs"
  },
  "gen": {
    "enable_normalization": "Enable Normalization",
    "enable_normalization_info": "Normalize audio volume to target peak level to prevent clipping or ensure consistent loudness.",
    "normalization_db": "Target Peak (dB)",
    "normalization_db_info": "Target peak level in decibels. -1.0 dB is standard safe peak. -0.1 dB is max.",
    "latent_shift": "Latent Shift",
    "latent_shift_info": "Shift applied to DiT latents before VAE decode. Default 0 (no shift). Negative values (e.g. -0.04) can reduce clipping.",
    "latent_rescale": "Latent Rescale",
    "latent_rescale_info": "Rescale factor for DiT latents before VAE decode. Default 1.0 (no rescale). Values < 1.0 (e.g. 0.91) can reduce clipping."
  }
}
